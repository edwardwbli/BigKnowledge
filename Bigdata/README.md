#Everything about Big data

###Spark
>Spark概览
>
>Spark 是一个通用的大规模数据快速处理引擎。可以简单理解为 Spark 就是一个大数据分布式处理框架。

>Spark是基于map reduce算法实现的分布式计算框架，但不同的是Spark的中间输出和结果输出可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地用于数据挖掘与机器学习等需要迭代的map reduce的算法中。


### Hadoop

>Hadoop就是解决了大数据（大到一台计算机无法进行存储，一台计算机无法在要求的时间内进行处理）的可靠存储和处理。
>Hadoop实现以下分布式存储和计算模型：
>
>HDFS，在由普通PC组成的集群上提供高可靠的文件存储，通过将块保存多个副本的办法解决服务器或硬盘坏掉的问题。

>MapReduce，通过简单的Mapper和Reducer的抽象提供一个编程模型（然而计算的细节需要工程人员自己实现），可以在一个由几十台上百台的PC组成的不可靠集群上并发地，分布式地处理大量的数据集，而把并发、分布式（如机器间通信）和故障恢复等计算细节隐藏起来。而Mapper和Reducer的抽象，又是各种各样的复杂数据处理都可以分解为的基本元素。这样，复杂的数据处理可以分解为由多个Job（包含一个Mapper和一个Reducer）组成的有向无环图（DAG）,然后每个Mapper和Reducer放到Hadoop集群上执行，就可以得出结果。

>####Hadoop的局限和不足

>1. 抽象层次低，需要手工编写代码来完成，使用上难以上手。
2. 只提供两个操作，Map和Reduce，表达力欠缺。
3. 一个Job只有Map和Reduce两个阶段（Phase），复杂的计算需要大量的Job完成，Job之间的依赖关系是由开发者自己管理的。
4. 处理逻辑隐藏在代码细节中，没有整体逻辑
5. 中间结果也放在HDFS文件系统中
6. ReduceTask需要等待所有MapTask都完成后才可以开始
7. 时延高，只适用Batch数据处理，对于交互式数据处理，实时数据处理的支持不够
8. 对于迭代式数据处理性能比较差

>不过也有许多技术对Hadoop进行改进，如```Pig```，```Cascading```，```JAQL```，```OOzie```，```Tez```，```Spark```等。







